# -*- coding: utf-8 -*-
"""
çŸ¥ä¹å‘å¸ƒé€‚é…å™¨ - v4.1 å¤šå›¾æµæ’ç‰ˆç‰ˆ
æ ¸å¿ƒå‡çº§ï¼š
1. æ”¯æŒå¤šå¼ å›¾ç‰‡ä¾æ¬¡æ’å…¥ï¼Œä¸å†ä»…é™é¦–å›¾
2. æ¨¡æ‹Ÿâ€œç¿»é¡µ -> æ¢è¡Œ -> ç²˜è´´â€çš„æ’ç‰ˆé€»è¾‘ï¼Œä½¿å›¾ç‰‡åˆ†å¸ƒåœ¨æ–‡ç« ä¸åŒä½ç½®
3. ä¿æŒå¼ºåˆ¶é…å›¾å’Œå°é¢ä¸Šä¼ çš„ç¨³å®šæ€§
"""

import asyncio
import re
import os
import httpx
import tempfile
import base64
import random
import urllib.parse
from typing import Dict, Any, List, Optional
from playwright.async_api import Page
from loguru import logger

from .base import BasePublisher, registry


class ZhihuPublisher(BasePublisher):
    async def publish(self, page: Page, article: Any, account: Any) -> Dict[str, Any]:
        temp_files = []
        try:
            logger.info("ğŸš€ å¼€å§‹çŸ¥ä¹å‘å¸ƒ (v4.1 å¤šå›¾æµæ’ç‰ˆç‰ˆ)...")

            # 1. å¯¼èˆª
            await page.goto(self.config["publish_url"], wait_until="networkidle", timeout=60000)
            await asyncio.sleep(5)

            # 2. å›¾åƒå‡†å¤‡
            # A. æå–æ­£æ–‡é“¾æ¥
            image_urls = re.findall(r'!\[.*?\]\(((?:https?://)?\S+?)\)', article.content)
            # B. æ¸…æ´—æ­£æ–‡
            clean_content = re.sub(r'!\[.*?\]\(.*?\)', '', article.content)

            # C. å¼ºåˆ¶è¡¥å›¾ç­–ç•¥
            if not image_urls:
                keyword = article.title[:10] if article.title else "technology"
                # ç”Ÿæˆ3å¼ ä¸åŒçš„å›¾ï¼Œç¡®ä¿æ–‡ç« ä¸°å¯Œåº¦
                for i in range(3):
                    seed = random.randint(1, 1000)
                    encoded_kw = urllib.parse.quote(f"high quality realistic photo of {keyword} {seed}")
                    url = f"https://image.pollinations.ai/prompt/{encoded_kw}?width=800&height=600&nologo=true"
                    image_urls.append(url)
                logger.info(f"ğŸ¨ å·²è‡ªåŠ¨ç”Ÿæˆ {len(image_urls)} å¼ é…å›¾é“¾æ¥")

            # D. ä¸‹è½½å›¾ç‰‡
            downloaded_paths = await self._download_images(image_urls)
            temp_files.extend(downloaded_paths)

            if not downloaded_paths:
                return {"success": False, "error_msg": "å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼Œæ— æ³•æ»¡è¶³å¼ºåˆ¶é…å›¾éœ€æ±‚"}

            # 3. å¡«å……æ ‡é¢˜
            await self._fill_title(page, article.title)

            # 4. å¡«å……æ­£æ–‡
            await self._fill_content_and_clean_ui(page, clean_content)

            # 5. ğŸŒŸ æ‰§è¡Œå¤šå›¾æ’ç‰ˆä¸Šä¼ 
            await self._handle_multi_image_upload(page, downloaded_paths)

            # 6. å‘å¸ƒæµç¨‹
            topic_word = getattr(article, 'keyword_text', article.title[:4])
            if not await self._handle_publish_process(page, topic_word):
                return {"success": False, "error_msg": "å‘å¸ƒç¡®è®¤ç¯èŠ‚å¤±è´¥"}

            return await self._wait_for_publish_result(page)

        except Exception as e:
            logger.exception(f"âŒ çŸ¥ä¹è„šæœ¬è‡´å‘½æ•…éšœ: {str(e)}")
            return {"success": False, "error_msg": str(e)}
        finally:
            for f in temp_files:
                if os.path.exists(f):
                    try:
                        os.remove(f)
                    except:
                        pass

    async def _download_images(self, urls: List[str]) -> List[str]:
        paths = []
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        async with httpx.AsyncClient(headers=headers, verify=False, follow_redirects=True) as client:
            # ä¸‹è½½å‰ 3 å¼ 
            for i, url in enumerate(urls[:3]):
                for attempt in range(2):
                    try:
                        resp = await client.get(url, timeout=20.0)
                        if resp.status_code == 200:
                            if len(resp.content) < 1000: continue
                            tmp_path = os.path.join(tempfile.gettempdir(), f"zh_v41_{random.randint(1000, 9999)}.jpg")
                            with open(tmp_path, "wb") as f:
                                f.write(resp.content)
                            paths.append(tmp_path)
                            logger.info(f"âœ… å›¾ç‰‡ {i + 1} ä¸‹è½½æˆåŠŸ")
                            break
                    except:
                        pass
        return paths

    async def _handle_multi_image_upload(self, page: Page, paths: List[str]):
        """
        å¤šå›¾æ’ç‰ˆé€»è¾‘ï¼š
        1. ç¬¬ä¸€å¼ è®¾ä¸ºå°é¢ + æ’å…¥æ–‡ç« é¡¶éƒ¨
        2. åç»­å›¾ç‰‡æ’å…¥æ–‡ç« ä¸­é—´æˆ–åº•éƒ¨
        """
        try:
            # Step 1: ä¸Šä¼ å°é¢ (ä½¿ç”¨ç¬¬ä¸€å¼ å›¾)
            logger.info("ğŸ–¼ï¸ æ­£åœ¨è®¾ç½®æ–‡ç« å°é¢...")
            cover_input = page.locator("input.UploadPicture-input").first
            if await cover_input.count() > 0:
                await cover_input.set_input_files(paths[0])
                await asyncio.sleep(3)

            # Step 2: éå†æ’å…¥æ­£æ–‡
            editor = page.locator(".public-DraftEditor-content").first
            await editor.click()

            for i, image_path in enumerate(paths):
                logger.info(f"ğŸ“ æ­£åœ¨æ’å…¥ç¬¬ {i + 1}/{len(paths)} å¼ å›¾ç‰‡...")

                if i == 0:
                    # ç¬¬ä¸€å¼ ï¼šå›åˆ°é¡¶éƒ¨æ’å…¥
                    await page.keyboard.press("Control+Home")
                    await page.keyboard.press("Enter")
                    await page.keyboard.press("ArrowUp")
                else:
                    # åç»­å›¾ç‰‡ï¼šæ¨¡æ‹Ÿå‘ä¸‹é˜…è¯»ç¿»é¡µï¼Œç„¶åæ’å…¥
                    # æŒ‰ 4 æ¬¡ PageDown (çº¦å¾€ä¸‹ç¿» 2-3 å±)
                    for _ in range(4):
                        await page.keyboard.press("PageDown")
                        await asyncio.sleep(0.2)

                    # å›è½¦æ¢è¡Œï¼Œè…¾å‡ºç©ºé—´
                    await page.keyboard.press("Enter")

                # æ‰§è¡Œç²˜è´´æ³¨å…¥
                await self._paste_image_via_js(page, image_path)

                # ç­‰å¾…ä¸Šä¼ å®Œæˆï¼Œé¿å…å¹¶å‘å†²çª
                await asyncio.sleep(5)

        except Exception as e:
            logger.error(f"å¤šå›¾ä¸Šä¼ æµç¨‹éƒ¨åˆ†å¤±è´¥: {e}")

    async def _paste_image_via_js(self, page: Page, image_path: str):
        """é€šç”¨ç²˜è´´å‡½æ•°ï¼šè¯»å–æœ¬åœ°å›¾ç‰‡å¹¶ä¼ªé€  Paste äº‹ä»¶"""
        with open(image_path, "rb") as f:
            b64_data = base64.b64encode(f.read()).decode('utf-8')

        await page.evaluate('''(data) => {
            const { b64 } = data;
            const byteCharacters = atob(b64);
            const byteNumbers = new Array(byteCharacters.length);
            for (let i = 0; i < byteCharacters.length; i++) {
                byteNumbers[i] = byteCharacters.charCodeAt(i);
            }
            const byteArray = new Uint8Array(byteNumbers);
            const blob = new Blob([byteArray], { type: 'image/jpeg' });
            const file = new File([blob], "auto_inserted.jpg", { type: 'image/jpeg' });

            const dt = new DataTransfer();
            dt.items.add(file);

            const editor = document.querySelector(".public-DraftEditor-content");
            const event = new ClipboardEvent("paste", {
                clipboardData: dt,
                bubbles: true,
                cancelable: true
            });
            editor.dispatchEvent(event);
        }''', {"b64": b64_data})

    async def _fill_title(self, page: Page, title: str):
        sel = "input[placeholder*='æ ‡é¢˜'], .WriteIndex-titleInput textarea"
        await page.wait_for_selector(sel)
        await page.fill(sel, title)

    async def _fill_content_and_clean_ui(self, page: Page, content: str):
        editor = ".public-DraftEditor-content"
        await page.wait_for_selector(editor)
        await page.click(editor)

        await page.evaluate('''(text) => {
            const dt = new DataTransfer();
            dt.setData("text/plain", text);
            const ev = new ClipboardEvent("paste", { clipboardData: dt, bubbles: true });
            document.querySelector(".public-DraftEditor-content").dispatchEvent(ev);
        }''', content)

        await asyncio.sleep(2)
        try:
            confirm = page.locator("button:has-text('ç¡®è®¤å¹¶è§£æ')").first
            if await confirm.is_visible(timeout=3000):
                await confirm.click()
        except:
            pass

    async def _handle_publish_process(self, page: Page, topic: str) -> bool:
        await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
        try:
            add_topic = page.locator("button:has-text('æ·»åŠ è¯é¢˜')").first
            if await add_topic.is_visible(timeout=2000):
                await add_topic.click()

            topic_input = page.locator("input[placeholder*='è¯é¢˜']").first
            await topic_input.fill(topic)
            await asyncio.sleep(2)
            suggestion = page.locator(".Suggestion-item, .PublishPanel-suggestionItem").first
            if await suggestion.is_visible(timeout=2000):
                await suggestion.click()
            else:
                await page.keyboard.press("Enter")
        except:
            pass

        final_btn = page.locator(
            "button.PublishPanel-submitButton, .WriteIndex-publishButton, button:has-text('å‘å¸ƒ')").last
        for _ in range(5):
            if await final_btn.is_enabled():
                await final_btn.click(force=True)
                return True
            await asyncio.sleep(2)
        return False

    async def _wait_for_publish_result(self, page: Page) -> Dict[str, Any]:
        for i in range(25):
            if "/p/" in page.url and "/edit" not in page.url:
                return {"success": True, "platform_url": page.url}
            await asyncio.sleep(1)
        return {"success": False, "error_msg": "å‘å¸ƒè¶…æ—¶"}


# æ³¨å†Œ
ZHIHU_CONFIG = {"name": "çŸ¥ä¹", "publish_url": "https://zhuanlan.zhihu.com/write", "color": "#0084FF"}
registry.register("zhihu", ZhihuPublisher("zhihu", ZHIHU_CONFIG))
