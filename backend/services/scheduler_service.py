# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨åŒ–è°ƒåº¦æœåŠ¡ - å·¥ä¸šåŠ å›ºç‰ˆ
è´Ÿè´£ï¼šå®šæ—¶æ‰«æå¾…å‘å¸ƒæ–‡ç« ã€è‡ªåŠ¨è§¦å‘æ”¶å½•æ£€æµ‹ã€å¤±è´¥é‡è¯•ã€åŠ¨æ€ä»»åŠ¡åŠ è½½
"""

import asyncio
import random
from typing import Optional, Dict, Any, List
from datetime import datetime
from loguru import logger
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from sqlalchemy.orm import Session

# å°è¯•å¯¼å…¥æ—¶åŒºï¼Œé˜²æ­¢ç¯å¢ƒç¼ºå¤±æŠ¥é”™
try:
    from pytz import timezone
except ImportError:
    timezone = None

from backend.services.geo_article_service import GeoArticleService
from backend.database.models import ScheduledTask, GeoArticle, Project, Keyword

# ğŸŒŸ ç»Ÿä¸€æ—¥å¿—ç»‘å®š
log = logger.bind(module="è°ƒåº¦ä¸­å¿ƒ")

class SchedulerService:
    def __init__(self):
        tz = timezone('Asia/Shanghai') if timezone else None
        # é…ç½®è°ƒåº¦å™¨ï¼Œè®¾ç½®è¾ƒé•¿çš„è¯¯ç«å®¹å¿æ—¶é—´
        self.scheduler = AsyncIOScheduler(
            timezone=tz,
            job_defaults={
                'misfire_grace_time': 60, # ğŸŒŸ å…è®¸é”™è¿‡æ—¶é—´å60ç§’å†…é‡è¯•
                'coalesce': True,         # ç§¯å‹çš„ä»»åŠ¡åªè·‘ä¸€æ¬¡
                'max_instances': 1        # åŒä¸€ä¸ªJobåŒæ—¶åªèƒ½è·‘ä¸€ä¸ªå®ä¾‹
            }
        )
        self.db_factory = None

        # ğŸŒŸ ä»»åŠ¡æ˜ å°„è¡¨
        self.task_registry = {
            "publish_task": self.check_and_publish_scheduled_articles,
            "monitor_task": self.auto_check_indexing_job
        }

    def set_db_factory(self, db_factory):
        self.db_factory = db_factory

    def init_default_tasks(self):
        """åˆå§‹åŒ–é»˜è®¤å®šæ—¶æ‰«æä»»åŠ¡"""
        if not self.db_factory: return
        db = self.db_factory()
        try:
            if db.query(ScheduledTask).count() == 0:
                defaults = [
                    ScheduledTask(
                        name="æ–‡ç« è‡ªåŠ¨å‘å¸ƒå¼•æ“",
                        task_key="publish_task",
                        cron_expression="*/1 * * * *",  # æ¯åˆ†é’Ÿæ‰«æä¸€æ¬¡
                        description="æ‰«æå¾…å‘å¸ƒæ–‡ç« å¹¶è§¦å‘æµè§ˆå™¨è‡ªåŠ¨åŒ–è„šæœ¬",
                        is_active=True
                    ),
                    ScheduledTask(
                        name="å…¨ç½‘æ”¶å½•å®æ—¶ç›‘æµ‹",
                        task_key="monitor_task",
                        cron_expression="*/5 * * * *",  # æ¯5åˆ†é’Ÿç›‘æµ‹ä¸€æ¬¡
                        description="é€šè¿‡AIæœç´¢å¼•æ“æ£€æŸ¥å·²å‘å¸ƒæ–‡ç« çš„æ”¶å½•çŠ¶æ€",
                        is_active=True
                    )
                ]
                db.add_all(defaults)
                db.commit()
                log.info("âœ… é»˜è®¤å®šæ—¶æ‰«æä»»åŠ¡åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            log.error(f"åˆå§‹åŒ–ä»»åŠ¡å¤±è´¥: {e}")
        finally:
            db.close()

    def _schedule_job(self, task: ScheduledTask):
        """å†…éƒ¨æ–¹æ³•ï¼šæ³¨å†Œ/æ›´æ–°å•ä¸ª Job"""
        func = self.task_registry.get(task.task_key)
        if not func:
            log.warning(f"âš ï¸ æœªæ‰¾åˆ°å¤„ç†å‡½æ•°: {task.task_key}")
            return

        if self.scheduler.get_job(task.task_key):
            self.scheduler.remove_job(task.task_key)

        if task.is_active:
            try:
                self.scheduler.add_job(
                    func,
                    CronTrigger.from_crontab(task.cron_expression),
                    id=task.task_key,
                    replace_existing=True,
                    misfire_grace_time=60 # ğŸŒŸ åŠ å›ºä¿æŠ¤
                )
                log.info(f"ğŸ“… ä»»åŠ¡è£…è½½æˆåŠŸ: [{task.name}] -> {task.cron_expression}")
            except Exception as e:
                log.error(f"âŒ Cron è¡¨è¾¾å¼è§£æé”™è¯¯ [{task.name}]: {e}")

    def load_jobs_from_db(self):
        """ä»æ•°æ®åº“åŠ è½½å¹¶æ³¨å†Œæ‰€æœ‰ä»»åŠ¡"""
        if not self.db_factory: return
        db = self.db_factory()
        try:
            tasks = db.query(ScheduledTask).all()
            for t in tasks:
                self._schedule_job(t)
        finally:
            db.close()

    def start(self):
        """å¯åŠ¨è°ƒåº¦å¼•æ“"""
        if not self.scheduler.running:
            self.init_default_tasks()
            self.load_jobs_from_db()
            self.scheduler.start()
            log.success("ğŸš€ [Scheduler] åŠ¨æ€è°ƒåº¦å¼•æ“å·²å…¨é¢å¯åŠ¨")

    def stop(self):
        """å®‰å…¨åœæ­¢"""
        if self.scheduler.running:
            self.scheduler.shutdown()
            log.info("ğŸ›‘ [Scheduler] è°ƒåº¦å¼•æ“å·²å®‰å…¨å…³é—­")

    def reload_task(self, task_id: int):
        """ç”¨æˆ·ä¿®æ”¹é…ç½®åï¼Œæ‰‹åŠ¨çƒ­æ›´æ–°"""
        if not self.db_factory: return
        db = self.db_factory()
        try:
            task = db.query(ScheduledTask).get(task_id)
            if task:
                self._schedule_job(task)
                return True
        finally:
            db.close()
        return False

    # ================= ğŸš€ æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ Job =================

    async def check_and_publish_scheduled_articles(self):
        """
        [Job] è‡ªåŠ¨æ‰«æå¹¶å‘å¸ƒ
        """
        if not self.db_factory: return
        db = self.db_factory()
        try:
            now = datetime.now()
            # æœç´¢ï¼šå¾…å‘å¸ƒ(scheduled) æˆ– å¤±è´¥é‡è¯•(failed ä¸” æ¬¡æ•°<3) ä¸” æ—¶é—´å·²åˆ°
            pending = db.query(GeoArticle).filter(
                ((GeoArticle.publish_status == "scheduled") |
                 ((GeoArticle.publish_status == "failed") & (GeoArticle.retry_count < 3))),
                GeoArticle.publish_time <= now
            ).all()

            if pending:
                log.info(f"ğŸ” [å‘å¸ƒæ‰«æ] å‘ç° {len(pending)} ç¯‡å¾…å‘å¸ƒæ–‡ç« ï¼Œå‡†å¤‡è§¦å‘è„šæœ¬...")
                service = GeoArticleService(db)
                for article in pending:
                    # ğŸŒŸ å…³é”®ï¼šä½¿ç”¨ create_task å¼‚æ­¥å¤„ç†ï¼Œé˜²æ­¢å¤šç¯‡æ–‡ç« å‘å¸ƒæ—¶äº’ç›¸é˜»å¡
                    asyncio.create_task(service.execute_publish(article.id))
        except Exception as e:
            log.error(f"å‘å¸ƒ Job è¿è¡Œå¼‚å¸¸: {e}")
        finally:
            db.close()

    async def auto_check_indexing_job(self):
        """
        [Job] è‡ªåŠ¨ç›‘æµ‹æ”¶å½•
        """
        if not self.db_factory: return
        db = self.db_factory()
        try:
            # æœç´¢ï¼šå·²å‘å¸ƒ ä½† æœªè¢«ç¡®è®¤æ”¶å½•çš„æ–‡ç« 
            pending = db.query(GeoArticle).filter(
                GeoArticle.publish_status == "published",
                GeoArticle.index_status != "indexed"
            ).all()

            if pending:
                log.info(f"ğŸ“¡ [æ”¶å½•æ‰«æ] å‘ç° {len(pending)} ç¯‡å·²å‘å¸ƒæ–‡ç« éœ€è¦æ£€æµ‹æ•ˆæœ...")
                service = GeoArticleService(db)
                for article in pending:
                    asyncio.create_task(service.check_article_index(article.id))
        except Exception as e:
            log.error(f"ç›‘æµ‹ Job è¿è¡Œå¼‚å¸¸: {e}")
        finally:
            db.close()

# å•ä¾‹æ¨¡å¼
_instance = SchedulerService()

def get_scheduler_service():
    return _instance